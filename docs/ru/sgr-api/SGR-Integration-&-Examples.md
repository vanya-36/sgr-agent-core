## üöÄ <strong>–ü—Ä–∏–º–µ—Ä—ã Python OpenAI Client</strong> - –ü–æ–ª–Ω–æ–µ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å –ø–æ—Ç–æ–∫–æ–≤–æ–π –ø–µ—Ä–µ–¥–∞—á–µ–π –∏ —É—Ç–æ—á–Ω–µ–Ω–∏—è–º–∏</summary>

–ü—Ä–æ—Å—Ç—ã–µ –ø—Ä–∏–º–µ—Ä—ã Python –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∫–ª–∏–µ–Ω—Ç–∞ OpenAI —Å —Å–∏—Å—Ç–µ–º–æ–π SGR Agent Core.

### –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è

```bash
pip install openai
```

### –ü—Ä–∏–º–µ—Ä 1: –ë–∞–∑–æ–≤—ã–π –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –∑–∞–ø—Ä–æ—Å

–ü—Ä–æ—Å—Ç–æ–π –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –∑–∞–ø—Ä–æ—Å –±–µ–∑ —É—Ç–æ—á–Ω–µ–Ω–∏–π.

```python
from openai import OpenAI

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–∞
client = OpenAI(
    base_url="http://localhost:8010/v1",
    api_key="dummy",  # –ù–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ —Å–µ—Ä–≤–µ—Ä–∞
)

# –í—ã–ø–æ–ª–Ω–∏—Ç—å –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –∑–∞–ø—Ä–æ—Å
response = client.chat.completions.create(
    model="sgr-agent",
    messages=[{"role": "user", "content": "Research BMW X6 2025 prices in Russia"}],
    stream=True,
    temperature=0.4,
)

# –í—ã–≤–µ—Å—Ç–∏ –ø–æ—Ç–æ–∫–æ–≤—ã–π –æ—Ç–≤–µ—Ç
for chunk in response:
    if chunk.choices[0].delta.content:
        print(chunk.choices[0].delta.content, end="")
```

### –ü—Ä–∏–º–µ—Ä 2: –ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π —É—Ç–æ—á–Ω–µ–Ω–∏–π

–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–æ–≤ –∞–≥–µ–Ω—Ç–∞ –Ω–∞ —É—Ç–æ—á–Ω–µ–Ω–∏–µ –∏ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞.

```python
import json
from openai import OpenAI

client = OpenAI(base_url="http://localhost:8010/v1", api_key="dummy")

# –®–∞–≥ 1: –ù–∞—á–∞–ª—å–Ω—ã–π –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –∑–∞–ø—Ä–æ—Å
print("–ù–∞—á–∞–ª–æ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è...")
response = client.chat.completions.create(
    model="sgr-agent",
    messages=[{"role": "user", "content": "Research AI market trends"}],
    stream=True,
    temperature=0,
)

agent_id = None
clarification_questions = []

# –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ—Ç–æ–∫–æ–≤–æ–≥–æ –æ—Ç–≤–µ—Ç–∞
for chunk in response:
    # –ò–∑–≤–ª–µ—á—å ID –∞–≥–µ–Ω—Ç–∞ –∏–∑ –ø–æ–ª—è model
    if chunk.model and chunk.model.startswith("sgr_agent_"):
        agent_id = chunk.model
        print(f"\nID –∞–≥–µ–Ω—Ç–∞: {agent_id}")

    # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∑–∞–ø—Ä–æ—Å—ã –Ω–∞ —É—Ç–æ—á–Ω–µ–Ω–∏–µ
    if chunk.choices[0].delta.tool_calls:
        for tool_call in chunk.choices[0].delta.tool_calls:
            if tool_call.function and tool_call.function.name == "clarification":
                args = json.loads(tool_call.function.arguments)
                clarification_questions = args.get("questions", [])

    # –í—ã–≤–µ—Å—Ç–∏ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ
    if chunk.choices[0].delta.content:
        print(chunk.choices[0].delta.content, end="")

# –®–∞–≥ 2: –û–±—Ä–∞–±–æ—Ç–∞—Ç—å —É—Ç–æ—á–Ω–µ–Ω–∏–µ, –µ—Å–ª–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ
if clarification_questions and agent_id:
    print(f"\n\n–¢—Ä–µ–±—É–µ—Ç—Å—è —É—Ç–æ—á–Ω–µ–Ω–∏–µ:")
    for i, question in enumerate(clarification_questions, 1):
        print(f"{i}. {question}")

    # –ü—Ä–µ–¥–æ—Å—Ç–∞–≤–∏—Ç—å —É—Ç–æ—á–Ω–µ–Ω–∏–µ
    clarification = "Focus on LLM market trends for 2024-2025, global perspective"
    print(f"\n–ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —É—Ç–æ—á–Ω–µ–Ω–∏—è: {clarification}")

    # –ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å —Å ID –∞–≥–µ–Ω—Ç–∞
    response = client.chat.completions.create(
        model=agent_id,  # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å ID –∞–≥–µ–Ω—Ç–∞ –∫–∞–∫ –º–æ–¥–µ–ª—å
        messages=[{"role": "user", "content": clarification}],
        stream=True,
        temperature=0,
    )

    # –í—ã–≤–µ—Å—Ç–∏ —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç
    for chunk in response:
        if chunk.choices[0].delta.content:
            print(chunk.choices[0].delta.content, end="")

print("\n\n–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
```

### –ü—Ä–∏–º–µ—Ä 3: –ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –∑–∞–ø—Ä–æ—Å —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º

–û—Ç–ø—Ä–∞–≤–∫–∞ –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ —Å –ª–æ–∫–∞–ª—å–Ω—ã–º —Ñ–∞–π–ª–æ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.

```python
import base64
from openai import OpenAI

client = OpenAI(base_url="http://localhost:8010/v1", api_key="dummy")

# –ü—Ä–æ—á–∏—Ç–∞—Ç—å –ª–æ–∫–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ –∑–∞–∫–æ–¥–∏—Ä–æ–≤–∞—Ç—å –≤ base64
with open("chart.png", "rb") as image_file:
    image_data = base64.b64encode(image_file.read()).decode("utf-8")
    image_base64 = f"data:image/png;base64,{image_data}"

# –ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –∑–∞–ø—Ä–æ—Å —Å –ª–æ–∫–∞–ª—å–Ω—ã–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º
response = client.chat.completions.create(
    model="sgr-agent",
    messages=[{
        "role": "user",
        "content": [
            {"type": "text", "text": "–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —ç—Ç–æ—Ç –≥—Ä–∞—Ñ–∏–∫ –∏ –∏—Å—Å–ª–µ–¥—É–π –ø–æ–∫–∞–∑–∞–Ω–Ω—ã–µ —Ç—Ä–µ–Ω–¥—ã"},
            {"type": "image_url", "image_url": {"url": image_base64}}
        ]
    }],
    stream=True,
    temperature=0.4,
)

# –í—ã–≤–µ—Å—Ç–∏ –ø–æ—Ç–æ–∫–æ–≤—ã–π –æ—Ç–≤–µ—Ç
for chunk in response:
    if chunk.choices[0].delta.content:
        print(chunk.choices[0].delta.content, end="")
```

**–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π:**
- URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (HTTP/HTTPS)
- –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ —Ñ–æ—Ä–º–∞—Ç–µ Base64 (`data:image/jpeg;base64,...` –∏–ª–∏ `data:image/png;base64,...`)

#### –ü—Ä–∏–º–µ—á–∞–Ω–∏—è –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é

- –ó–∞–º–µ–Ω–∏—Ç–µ `localhost:8010` –Ω–∞ URL –≤–∞—à–µ–≥–æ —Å–µ—Ä–≤–µ—Ä–∞
- `api_key` –º–æ–∂–µ—Ç –±—ã—Ç—å –ª—é–±–æ–π —Å—Ç—Ä–æ–∫–æ–π –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ —Å–µ—Ä–≤–µ—Ä–∞
- ID –∞–≥–µ–Ω—Ç–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç—Å—è –≤ –ø–æ–ª–µ `model` –≤–æ –≤—Ä–µ–º—è –ø–æ—Ç–æ–∫–æ–≤–æ–π –ø–µ—Ä–µ–¥–∞—á–∏
- –í–æ–ø—Ä–æ—Å—ã —É—Ç–æ—á–Ω–µ–Ω–∏—è –æ—Ç–ø—Ä–∞–≤–ª—è—é—Ç—Å—è —á–µ—Ä–µ–∑ `tool_calls` —Å –∏–º–µ–Ω–µ–º —Ñ—É–Ω–∫—Ü–∏–∏ `clarification`
- –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ ID –∞–≥–µ–Ω—Ç–∞ –∫–∞–∫ –∏–º—è –º–æ–¥–µ–ª–∏ –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è —Ä–∞–∑–≥–æ–≤–æ—Ä–∞

______________________________________________________________________

## <summary>‚ö° <strong>–ü—Ä–∏–º–µ—Ä—ã cURL API</strong> - –ü—Ä—è–º—ã–µ HTTP –∑–∞–ø—Ä–æ—Å—ã —Å –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏–µ–º –∞–≥–µ–Ω—Ç–∞ –∏ –ø–æ—Ç–æ–∫–æ–º —É—Ç–æ—á–Ω–µ–Ω–∏–π</summary>

–°–∏—Å—Ç–µ–º–∞ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –ø–æ–ª–Ω–æ—Å—Ç—å—é —Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π —Å OpenAI API —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–º–∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—è–º–∏ –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏—è –∞–≥–µ–Ω—Ç–∞ –∏ —É—Ç–æ—á–Ω–µ–Ω–∏–π.

### –ë–∞–∑–æ–≤—ã–π –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –∑–∞–ø—Ä–æ—Å

```bash
curl -X POST "http://localhost:8010/v1/chat/completions" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "sgr_agent",
    "messages": [{"role": "user", "content": "Research BMW X6 2025 prices in Russia"}],
    "stream": true,
    "max_tokens": 1500,
    "temperature": 0.4
  }'
```

### –ü–æ—Ç–æ–∫ –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏—è –∞–≥–µ–Ω—Ç–∞ –∏ —É—Ç–æ—á–Ω–µ–Ω–∏–π

–ö–æ–≥–¥–∞ –∞–≥–µ–Ω—Ç—É —Ç—Ä–µ–±—É–µ—Ç—Å—è —É—Ç–æ—á–Ω–µ–Ω–∏–µ, –æ–Ω –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —É–Ω–∏–∫–∞–ª—å–Ω—ã–π ID –∞–≥–µ–Ω—Ç–∞ –≤ –ø–æ–ª–µ model –ø–æ—Ç–æ–∫–æ–≤–æ–≥–æ –æ—Ç–≤–µ—Ç–∞. –ó–∞—Ç–µ–º –≤—ã –º–æ–∂–µ—Ç–µ –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å —Ä–∞–∑–≥–æ–≤–æ—Ä, –∏—Å–ø–æ–ª—å–∑—É—è —ç—Ç–æ—Ç ID –∞–≥–µ–Ω—Ç–∞.

#### –®–∞–≥ 1: –ù–∞—á–∞–ª—å–Ω—ã–π –∑–∞–ø—Ä–æ—Å

```bash
curl -X POST "http://localhost:8010/v1/chat/completions" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "sgr_agent",
    "messages": [{"role": "user", "content": "Research AI market trends"}],
    "stream": true,
    "max_tokens": 1500,
    "temperature": 0
  }'
```

#### –®–∞–≥ 2: –ê–≥–µ–Ω—Ç –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ—Ç —É—Ç–æ—á–Ω–µ–Ω–∏–µ

–ü–æ—Ç–æ–∫–æ–≤—ã–π –æ—Ç–≤–µ—Ç –≤–∫–ª—é—á–∞–µ—Ç ID –∞–≥–µ–Ω—Ç–∞ –≤ –ø–æ–ª–µ model:

```json
{
  "model": "sgr_agent_b84d5a01-c394-4499-97be-dad6a5d2cb86",
  "choices": [{
    "delta": {
      "tool_calls": [{
        "function": {
          "name": "clarification",
          "arguments": "{\"questions\":[\"Which specific AI market segment are you interested in (LLM, computer vision, robotics)?\", \"What time period should I focus on (2024, next 5 years)?\", \"Are you looking for global trends or specific geographic regions?\", \"Do you need technical analysis or business/investment perspective?\"]}"
        }
      }]
    }
  }]
}
```

#### –®–∞–≥ 3: –ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å —Å ID –∞–≥–µ–Ω—Ç–∞

```bash
curl -X POST "http://localhost:8010/v1/chat/completions" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "sgr_agent_b84d5a01-c394-4499-97be-dad6a5d2cb86",
    "messages": [{"role": "user", "content": "Focus on LLM market trends for 2024-2025, global perspective, business analysis"}],
    "stream": true,
    "max_tokens": 1500,
    "temperature": 0
  }'
```

### –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∞–≥–µ–Ω—Ç–∞–º–∏

```bash
# –ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ—Ö –∞–∫—Ç–∏–≤–Ω—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤
curl http://localhost:8010/agents

# –ü–æ–ª—É—á–∏—Ç—å —Å–æ—Å—Ç–æ—è–Ω–∏–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –∞–≥–µ–Ω—Ç–∞
curl http://localhost:8010/agents/{agent_id}/state

# –ü—Ä—è–º–æ–π endpoint —É—Ç–æ—á–Ω–µ–Ω–∏—è
curl -X POST "http://localhost:8010/agents/{agent_id}/provide_clarification" \
  -H "Content-Type: application/json" \
  -d '{
    "messages": [{"role": "user", "content": "Focus on luxury models only"}],
    "stream": true
  }'
```
